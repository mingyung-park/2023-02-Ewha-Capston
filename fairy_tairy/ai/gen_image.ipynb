{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBiQfE3WiUeu/HdaQq90oB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mingyung-park/2023-02-Ewha-Capston/blob/main/fairy_tairy/ai/gen_image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AahPZ7-rlQ7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path='Eunju2834/LoRA_oilcanvas_style' #FineTuning Model Path\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "pipe.unet.load_attn_procs(model_path)\n",
        "pipe.to(device)\n",
        "\n",
        "neg_prompt='''FastNegativeV2,(bad-artist:1.0), (loli:1.2),\n",
        "    (worst quality, low quality:1.4), (bad_prompt_version2:0.8),\n",
        "    bad-hands-5,lowres, bad anatomy, bad hands, ((text)), (watermark),\n",
        "    error, missing fingers, extra digit, fewer digits, cropped,\n",
        "    worst quality, low quality, normal quality, ((username)), blurry,\n",
        "    (extra limbs), bad-artist-anime, badhandv4, EasyNegative,\n",
        "    ng_deepnegative_v1_75t, verybadimagenegative_v1.3, BadDream,\n",
        "    (three hands:1.1),(three legs:1.1),(more than two hands:1.4),\n",
        "    (more than two legs,:1.2),badhandv4,EasyNegative,ng_deepnegative_v1_75t,verybadimagenegative_v1.3,(worst quality, low quality:1.4),text,words,logo,watermark,\n",
        "    '''\n",
        "\n",
        "\n",
        "def get_image(prompt):\n",
        "    image = pipe(prompt, negative_prompt=neg_prompt,num_inference_steps=30, guidance_scale=7.5).images[0]\n",
        "    image.save(r\".\\fairy_tairy\\ai\\testimg\")\n",
        "    return image"
      ],
      "metadata": {
        "id": "qYRKE0Pnrpy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "base_text = open(\"./ai/genTextBase.txt\",'r', encoding='utf-8').readlines()\n",
        "openai.api_key=\"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\"\n",
        "\n",
        "def get_prompt(content):\n",
        "    completion = openai.Completion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": f\"{base_text} {content.strip()}\"},]\n",
        "    )\n",
        "    generated_text = completion[\"choices\"][0][\"message\"][\"content\"]\n",
        "    output_text=generated_text.split('\\n')\n",
        "    prompts = [v for v in output_text if v]\n",
        "    return prompts\n"
      ],
      "metadata": {
        "id": "uxUFRMmMr1n7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}